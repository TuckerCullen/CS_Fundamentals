{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hash Tables \n",
    "\n",
    "Hash tables are one of the most widly used data structures since when implemented correctly, they allow for essentially O(1) time lookups. Entries in a hash table consist of a key and a value. The value is what is stored in the table, and the key is a unique identifier used to find the place in the hash table in which to put the value. \n",
    "\n",
    "Or order to determine where in the hash table to put a certain value, the key is passed through a hash function. This hash function maps the key to an index. In order to your hash table to be most effecient, you want the size of hash table (m) to be the same as the number of values you want to put into the hash table (n). The proportion of the number of values stores in hash table to the hash table size (n/m) is known as the **load factor ($\\alpha$)**. \n",
    "\n",
    "Sometimes two keys keys can map to the same index, this is refered to as a **collision**. There are a couple of different ways to resolve collisions:\n",
    "\n",
    "1. **Chaining** - one of the easiest to implement collision resolution techniques, chaining involves using a linked list to chain together values with keys that map to the same address. A hash table with chaining implemented is essentially an array of linked lists. While easy to implement, this method is not the most space effecient since it uses two different underlying data structures. Additionally, if a chain becomes long hash table accessing can start to behave closer to O(n) time, since searching through a linked list is O(n). \n",
    "\n",
    "2. **Double (or triple, quadruple, etc) Hashing** -  involves applying additional hash functions to any keys that collide. The additional hash functions can all be the same or they can be different hash functions, as long as the hash functions are applied in the same order each time. This method does not add any space complexity. However, eventually all open slots in a hash table can fill up which will require a **rehashing**. This is where a new hash table is created that is double the size of the old table, and all the entries in the original are rehashed into the new table. This is essentially the same method that is used for dynamic array resizing. \n",
    "\n",
    "3. **Linear Probing** - Linear Probing involves going to the next availble spot in a hash table when the inital spot is full. This does not add to the space complexity, but does induce clustering into the hash table (where values are clustered together in certain regions of the hash table). Similar to dealing with a long chain, when there is a lot of clustering collisions can start to take closer to O(n) time to resolve. \n",
    "\n",
    "4. **Quadratic Probing** - Quadratic probing is the same as linear probing, but instead of going to the immediately adjacent slots you first go 1^2 slots away, then if that is full you go 2^2 slots away, then 3^2 slots away, and so on and so on. \n",
    "\n",
    "If you make a hash table too small you'll have a lot of collisions which increases the time complexity, but if you make it too big then you risk wasting a lot of memory. Generally, a load factor of around $\\alpha = 0.75$ is considered a good balance between time and space complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dicts : Python's built in HashMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'tucker', 'age': 22, 'eyes': 'blue', 'hair': 'blonde'}\n",
      "{'key1': 'default_value', 'key2': 'default_value', 'key3': 'default_value'}\n",
      "tucker\n",
      "tucker\n",
      "[('name', 'tucker'), ('age', 22), ('eyes', 'blue'), ('hair', 'blonde')]\n",
      "['name', 'age', 'eyes', 'hair']\n",
      "{'name': 'tucker', 'age': 22, 'eyes': 'blue'}\n",
      "{'name': 'tucker', 'age': 22, 'eyes': 'blue', 'height': \"5'10\"}\n",
      "{'name': 'tucker', 'age': 22, 'eyes': 'blue'}\n",
      "blue\n",
      "150\n",
      "{'name': 'tucker', 'age': 22, 'eyes': 'blue', 'weight': '150'}\n",
      "['tucker', 22, 'blue', '150']\n",
      "{'name': 'tucker', 'age': 22, 'eyes': 'blue', 'weight': '150', 'address': '123 main street', 'organ_donor': True}\n"
     ]
    }
   ],
   "source": [
    "hash_map = {\n",
    "    \"name\" : \"tucker\",\n",
    "    \"age\" : 22,\n",
    "    \"eyes\" : \"blue\",\n",
    "    \"hair\" : \"blonde\"\n",
    "           }\n",
    "\n",
    "#Make a COPY of the dict\n",
    "new_hash_map = hash_map.copy()\n",
    "print(new_hash_map)\n",
    "\n",
    "# Initalize a new dicts with specified keys and a default value\n",
    "print(hash_map.fromkeys([\"key1\", \"key2\", \"key3\"], \"default_value\"))\n",
    "\n",
    "# Two ways to get a value from the key \n",
    "print(hash_map.get(\"name\")) \n",
    "print(hash_map[\"name\"])\n",
    "assert hash_map.get(\"name\") == hash_map[\"name\"]\n",
    "\n",
    "# display a list of items, MUST CAST TO LIST \n",
    "print(list(hash_map.items()))\n",
    "\n",
    "# get a list of the dicts keys\n",
    "print(list(hash_map.keys()))\n",
    "\n",
    "# remove item with certain key \n",
    "hash_map.pop(\"hair\")\n",
    "print(hash_map)\n",
    "\n",
    "# insert a new key val pair \n",
    "hash_map[\"height\"] = \"5'10\"\n",
    "print(hash_map)\n",
    "\n",
    "# remove the last inserted item \n",
    "hash_map.popitem()\n",
    "print(hash_map)\n",
    "\n",
    "# get a specified key, or insert if it doesnt exsist\n",
    "print(hash_map.setdefault(\"eyes\", \"brown\"))\n",
    "print(hash_map.setdefault(\"weight\", \"150\"))\n",
    "print(hash_map)\n",
    "\n",
    "# return all values in a dict \n",
    "print(list(hash_map.values()))\n",
    "\n",
    "# update a dict with specified key value pairs (essentially add a dict to the present dict)\n",
    "hash_map.update({\"address\" : \"123 main street\", \"organ_donor\" : True})\n",
    "print(hash_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sets : Pythons Hash Set (only values, no keys)\n",
    "\n",
    "Sets are a good way to store a list of values that you need to keep track of, since you can check if a value exsists in a set in O(1) time. \n",
    "\n",
    "Sets are unordered, unchangable, and do not allow duplicates. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'english', 'math', 'history', 'biology', 'french'}\n",
      "yes, english is in the set\n",
      "no, physics is not in the set\n",
      "{32, 1, 2, 6, 14, 19}\n",
      "{6, 14}\n",
      "items in set1 but not in set 2:  {1, 19}\n",
      "items in set2 but not in set 1:  {32, 2}\n",
      "items in either of the sets but NOT both {32, 1, 2, 19}\n",
      "Are set1 and set2 disjoint? False\n",
      "Are set1 and set3 disjoint? True\n",
      "is set 1 a subset of set2? False\n",
      "is set4 a subset of set1? True\n",
      "is set1 a superset of set4? True\n"
     ]
    }
   ],
   "source": [
    "hash_set = {\"math\", \"english\", \"history\", \"french\"}\n",
    "\n",
    "# add to a set \n",
    "hash_set.add(\"biology\")\n",
    "print(hash_set)\n",
    "\n",
    "# Check if a value is in a set (in theta(1) time!)\n",
    "if \"english\" in hash_set:\n",
    "    print(\"yes, english is in the set\")\n",
    "else:\n",
    "    print(\"no, english is not in the set\")\n",
    "    \n",
    "if \"physics\" in hash_set:\n",
    "    print(\"yes, physics is in the set\")\n",
    "else:\n",
    "    print(\"no, physics is not in the set\")\n",
    "\n",
    "    \n",
    "# COMPARING TWO SETS -------------------------------------\n",
    "\n",
    "set1 = {1, 6, 14, 19}\n",
    "set2 = {2, 6, 14, 32}\n",
    "set3 = {4, 16, 90}\n",
    "set4 = {1, 6}\n",
    "\n",
    "# get UNION of sets (two ways)\n",
    "print(set1.union(set2))\n",
    "assert (set1 | set2) == (set1.union(set2))\n",
    "\n",
    "# INTERSECTION of sets\n",
    "print(set1.intersection(set2))\n",
    "assert (set1 & set2) == set1.intersection(set2)\n",
    "\n",
    "# DIFFERENCE between sets \n",
    "print(\"items in set1 but not in set 2: \",set1.difference(set2)) \n",
    "print(\"items in set2 but not in set 1: \", set2.difference(set1)) \n",
    "assert (set1 - set2) == set1.difference(set2)\n",
    "\n",
    "# SYMMETRIC Difference\n",
    "print(\"items in either of the sets but NOT both\", set1.symmetric_difference(set2))\n",
    "assert (set1 ^ set2) == set1.symmetric_difference(set2)\n",
    "\n",
    "# Are the sets DISJOINT? (do they have nothing in common?)\n",
    "print(\"Are set1 and set2 disjoint?\", set1.isdisjoint(set2))\n",
    "print(\"Are set1 and set3 disjoint?\", set1.isdisjoint(set3))\n",
    "\n",
    "# SUBSET?\n",
    "print(\"is set 1 a subset of set2?\", set1.issubset(set2))\n",
    "print(\"is set4 a subset of set1?\", set4.issubset(set1))\n",
    "print(\"is set1 a superset of set4?\", set1.issuperset(set4))\n",
    "\n",
    "#OTHER FUNCTIONS \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
